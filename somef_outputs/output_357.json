{
  "application_domain": [
    {
      "confidence": 0.8440774582649828,
      "result": {
        "type": "String",
        "value": "Semantic web"
      },
      "technique": "supervised_classification"
    }
  ],
  "authors": [
    {
      "confidence": 1,
      "result": {
        "affiliation": "California Institute of Technology Library",
        "email": "mhucka@caltech.edu",
        "identifier": "https://orcid.org/0000-0001-9105-5960",
        "type": "String",
        "value": "Michael Hucka"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "affiliation": "British Library",
        "email": "digitalresearch@bl.uk",
        "identifier": "https://orcid.org/0000-0003-3733-8120",
        "type": "String",
        "value": "Mia Ridge"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "affiliation": "Biblioth\u00e8que nationale de France",
        "email": "jean-philippe.moreux@bnf.fr",
        "identifier": "https://orcid.org/0000-0001-6335-0903",
        "type": "String",
        "value": "Jean-Philippe Moreux"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "affiliation": "University of Texas at Austin",
        "type": "String",
        "value": "Hannah Moutran"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "code_of_conduct": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Code of Conduct\n\nThe AI4LAM Code of Conduct covers our behavior as members of the AI4LAM Community in any forum or setting, including the [AI4LAM-Discuss](https://groups.google.com/g/ai4lam) mailing list, the [AI4LAM Slack workspace](https://ai4lam.slack.com/join/shared_invite/zt-1omthldn8-9vrGySjIRdija1nKQm0ltA#/shared-invite/email), the [AI4LAM community Google Drive](https://drive.google.com/drive/folders/1GJ0IJ0q11eYU0HZyQyNK_LP81fi1NsE8), remote and in-person meetings, private correspondence related to AI4LAM, source code repositories affiliated with AI4LAM, and discussion forums associated with source code repositories.\n\n## Community Norms and Expectations\n\nAI4LAM\u2019s core values include being an inclusive, diverse, international and safe community. As an international community, we are sensitive to many different social and cultural norms around language and behaviour, and we strive to conduct ourselves, online and in person, in ways that are unlikely to cause offense. AI4LAM members communicate primarily in English, recognising that English is not the native language for many in the community. We therefore strive to express ourselves simply and clearly, remembering that unnecessary use of jargon and slang will be a barrier to understanding for many of our colleagues. We recognize that not everyone may want or be able to travel internationally for AI4LAM events, and we strive to provide opportunities for remote participation whenever possible.\n\n## Anti-Harassment\n\nWe are a community of professionals, and we conduct ourselves professionally. The AI4LAM community is dedicated to providing a harassment-free collaboration experience for everyone regardless of gender, sexual orientation, disability, physical appearance, race, religion, faith, or anything else. We do not tolerate harassment of community participants in any form. Sexual or discriminatory language and imagery is not appropriate for any venue, including event presentations, email lists, teleconferences, and in-person gatherings. Participants violating these rules may be sanctioned or expelled at the discretion of the event of community coordinators, and their details provided to partner institutions.\n\nHarassment includes, but is not limited to:\n\n* Offensive verbal comments, insults, or jokes related to physical or intellectual ability, gender, sexual orientation, disability, physical appearance, race, religion, etc.\n* Discriminatory images in public spaces, including but not limited to sexually explicit or violent material\n* Deliberate intimidation, violent threats or language directed against another person\n* Stalking, or unwanted following\n* Harassing photography or recording\n* Sustained disruption of talks or other communication\n* Inappropriate or unwanted physical contact, and unwelcome sexual attention\n* Posting (or threatening to post) other people\u2019s personally identifying information\n* Advocating for, or encouraging, any of the above behaviour\n* Repeated harassment of others. In general, if someone asks you to stop, then stop\n\nAs this document outlines, participants in the AI4LAM community seek to foster a positive and supportive environment. We pride ourselves on building a productive, happy, and flexible community that can welcome new ideas in a complex field and foster collaboration between groups that ultimately share the same needs, interests, and goals.\n\nIndividuals who violate these guidelines will be notified and asked to change their behaviour. Repeated violations may result in loss of membership in project groups, revocation of special access to project resources, and/or loss of access to project communication channels (AI4LAM-Discuss email list, Slack channels, and others). Repeat offenders may be asked to stop participating or directed to filter their participation through another member of their institution (if applicable).\n\nIf a participant engages in harassing behaviour, the community organisers may take any action they deem appropriate, including warning the offender, or immediate expulsion from the event or communication channel. Participants asked, by anyone, to stop any harassing behaviour are expected to comply immediately.\n\n## Reporting Guidelines\n\nIf you are being harassed, notice that someone else is being harassed, or have any other concerns, please contact a member of the event organizing team and/or AI4LAM Secretariat ([secretariat@ai4lam.org](secretariat@ai4lam.org)). If you believe anyone is in physical danger, please notify appropriate law enforcement first. If you are unsure what law enforcement agency is appropriate, please include this in your report and we will attempt to notify them.\n"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/CODE_OF_CONDUCT.md",
      "technique": "file_exploration"
    }
  ],
  "code_repository": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AI4LAM/awesome-ai4lam"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mhucka/awesome-ai4lam"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "continuous_integration": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.github/workflows/yaml-linter.yml"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.github/workflows/bad-link-reporter.yml"
      },
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.github/workflows/markdown-linter.yml"
      },
      "technique": "file_exploration"
    }
  ],
  "contributing_guidelines": [
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "# Guidelines for contributing to this project\n\nAny constructive contributions \u2013 reports of problems, suggestions for additions or other improvements, and more \u2013 are welcome.\n\n## Conduct\n\nEveryone is asked to read and respect the [code of conduct](CODE_OF_CONDUCT.md) before participating in this project.\n\n## Submitting contributions\n\nThe best way to contribute an addition is to figure out where it belongs in the existing list, then use the [pull request facility on GitHub](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests) to propose the addition.\n\nThe community will review your pull request and may ask you for additional changes. If you have any questions, please don't hesitate to ask (we are trying to be as helpful as possible).\n\nThe second best way to make a contribution is to use [issue tracker](https://github.com/ai4lam/awesome-ai4lam/issues) on GitHub to suggest an addition or report a problem. Create a new issue and include as much information as necessary to help us understand where to incorporate your suggestion. If you're not sure where an addition should go, just ask!\n"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/CONTRIBUTING.md",
      "technique": "file_exploration"
    }
  ],
  "date_created": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2023-11-17T23:46:33Z"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "2023-11-17"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "date_published": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "2024-02-21"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "date_updated": [
    {
      "confidence": 1,
      "result": {
        "type": "Date",
        "value": "2025-09-18T12:50:01Z"
      },
      "technique": "GitHub_API"
    }
  ],
  "description": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A list of awesome AI in libraries, archives, and museum collections from around the world \ud83d\udd76\ufe0f"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "A curated list of resources, projects, and tools for using Artificial Intelligence in Libraries, Archives, and Museums"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introduction",
        "parent_header": [
          "Awesome AI for LAM <a href=\"https://github.com/sindresorhus/awesome\"><img alt=\"Awesome\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/awesome-list-badge.svg\" /></a>"
        ],
        "type": "Text_excerpt",
        "value": "This list is a collection of resources, tools, projects, and other materials for professionals and enthusiasts in the Libraries, Archives, and Museums (LAM) sector. You might also know this as the GLAM (galleries, libraries, archives and museums) or CHI (cultural heritage institutions) sector, or be more familiar with the term 'memory institutions'. However you describe the field, if you know of an AI, machine learning, big data or data science project, event or resource related to collections, please share it here!\n\nThis list is maintained by the [AI4LAM](https://www.ai4lam.org/) community. Its aim is to support knowledge sharing, innovation, and collaboration in applying AI to LAM.\n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "Introductions to AI",
        "parent_header": [
          "Awesome AI for LAM <a href=\"https://github.com/sindresorhus/awesome\"><img alt=\"Awesome\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/awesome-list-badge.svg\" /></a>",
          "Learning Resources<a title=\"Suggest an addition to the list!\" href=\"https://forms.gle/aPA41GT5AmbxrTwq5\"><img alt=\"Click button to suggest an addition\" align=\"right\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg\"></a>"
        ],
        "type": "Text_excerpt",
        "value": "- [Elements of AI](https://www.elementsofai.com/) \u2013 free course by MinnaLearn & University of Helsinki\n- [Introduction to AI for GLAM](https://carpentries-incubator.github.io/machine-learning-librarians-archivists/) \u2013 by Library Carpentries\n- [AI Guide by the AI Pedagogy Project](https://aipedagogy.org) \u2013 collection of materials by [metaLAB](https://mlml.io/about/)\n- [Slides from FF23 workshop on _Intro to AI for GLAM_](https://docs.google.com/presentation/d/1dVdS3u-XS2RDexNm3RlwICCsh5gBmdi1pBARgIGnPN8) and [shared notes](https://pad.carpentries.org/intro-ai-ff2023)\n- [Machine Learning 101](https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/edit#slide=id.g168a3288f7_0_58) \u2013 by Jason Mayes from Google\n- [Codecademy AI Courses](https://www.codecademy.com/catalog/subject/artificial-intelligence) \u2013 many topics; some lessons are free, some are for-fee\n- [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html), by Sebastian Raschka\n- [Dive into Deep Learning](https://d2l.ai/index.html), by Zhang et al.\n- [A Collection of AI Demos to Discover and Explore](https://exploreai.jisc.ac.uk/)\n- [DeepLearning.AI Short Courses](https://www.deeplearning.ai/short-courses/), a free courses from a platform created by Andrew Ng\n- [Introduction to Hugging Face](https://www.codecademy.com/learn/intro-to-hugging-face), a free course by Codecademy\n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "header_analysis"
    },
    {
      "confidence": 0.8727872760607983,
      "result": {
        "original_header": "Awesome AI for LAM <a href=\"https://github.com/sindresorhus/awesome\"><img alt=\"Awesome\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/awesome-list-badge.svg\" /></a>",
        "type": "Text_excerpt",
        "value": "A curated list of resources, projects, and tools for using Artificial Intelligence in Libraries, Archives, and Museums. \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8469578190288016,
      "result": {
        "original_header": "Learning Resources<a title=\"Suggest an addition to the list!\" href=\"https://forms.gle/aPA41GT5AmbxrTwq5\"><img alt=\"Click button to suggest an addition\" align=\"right\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg\"></a>",
        "type": "Text_excerpt",
        "value": "Please note: the appearance of a resource on this list does not constitute an official endorsement by AI4LAM.\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8941096582266345,
      "result": {
        "original_header": "AI in galleries, libraries, archives and museums",
        "type": "Text_excerpt",
        "value": "- The [AI4LAM YouTube channel](https://www.youtube.com/@ai4lam120/videos) has introductory presentations on many topics\n- The [CENL \"AI in Libraries\" network group](https://www.cenl.org/networkgroups/ai-in-libraries-network-group/) is also organizing webinars on AI implementation in GLAM.\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9365700400675581,
      "result": {
        "original_header": "Tools and Frameworks<a title=\"Suggest an addition to the list!\" href=\"https://forms.gle/aPA41GT5AmbxrTwq5\"><img alt=\"Click button to suggest an addition\" align=\"right\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg\"></a>",
        "type": "Text_excerpt",
        "value": "Note: datasets for training and testing are listed in a [separate section](#datasets) of this document.\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9692743493634622,
      "result": {
        "original_header": "Document analysis, transcription, and labeling",
        "type": "Text_excerpt",
        "value": "- [Arkindex](https://teklia.com/blog/arkindex-goes-open-source/) \u2013 open-source platform for managing &amp; processing collections of digitized documents\n- [Callico](https://teklia.com/blog/open-sourcing-callico/) \u2013 open-source web platform for document annotation\n- [Coconut Libtool](https://www.coconut-libtool.com) \u2013 web-based textual analysis tool designed to assist social scientists, librarians, or anyone in data analysis\n- [Distributed Annotation 'n' Enrichment (DANE)](https://github.com/CLARIAH/DANE#readme) \u2013 compute task assignment & file storage for automatic annotation of content ([CLARIAH](https://www.clariah.nl/about-clariah), Norway)\n- [HTRFLOW demo](https://huggingface.co/spaces/Riksarkivet/htr_demo) and associated [GitHub repo](https://github.com/Swedish-National-Archives-AI-lab/htrflow_app) \u2013 explore AI models for Handwritten Text Recogntion (Swedish National Archives)\n- [Label Studio](https://labelstud.io) \u2013 data labeling platform to fine-tune LLMs, prepare training data, or validate AI models\n- [OCR correction](https://bnl.public.lu/en.html) \u2013 OCR correction tools (Biblioth\u00e8que nationale, Luxembourg)\n- [Surya](https://github.com/VikParuchuri/surya#readme) \u2013 multilingual document OCR toolkit with line-level text detection\n- [Text models from the National Library of Sweden](https://huggingface.co/KBLab) \u2013 available on Hugging Face\n- [Transkribus](https://readcoop.eu/transkribus/) \u2013 transcription, recognition, & searching of historical documents \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9669894983165542,
      "result": {
        "original_header": "Audio and video analysis, transcription, and labeling",
        "type": "Text_excerpt",
        "value": "- [Acoustic models from the National Library of Sweden](https://huggingface.co/KBLab) \u2013 available on Hugging Face\n- [Annotorious](https://annotorious.github.io) \u2013 JavaScript image annotation library\n- [Audiovisual Metadata Platform (AMP)](https://uisapp2.iu.edu/confluence-prd/display/AMP/AMP%3A+Audiovisual+Metadata+Platform) \u2013 generation of metadata for discovery & use of digital audio & video collections (Indiana U., USA)\n- [CAMPI](https://kilthub.cmu.edu/articles/preprint/CAMPI_Computer-Aided_Metadata_Generation_for_Photo_archives_Initiative/12791807) \u2013 Computer-Aided Metadata Generation for Photo archives Initiative (Carnegie Mellonw U., USA)\n- [ELAN](https://archive.mpi.nl/tla/elan) \u2013 addS textual annotations to audio and/or video recordings (Max Planck Institute for Psycholinguistics, The Netherlands)\n- [inaFaceAnalyzer](https://github.com/ina-foss/inaFaceAnalyzer#readme) \u2013 Python toolbox for face-based description of gender representation in media (Institut National de l'Audiovisuel, France)\n- [Newspaper Navigator](https://labs.loc.gov/work/experiments/newspaper-navigator/) \u2013 explore visual & textual content in the _Chronicling America_ digitized newspaper collection (Library of Congress, USA)\n- [Oodi](https://medium.com/headai-customer-stories/customer-story-oodi-1d1ef2554bb6) \u2013 virtual information assistant (Helsinki Central Library)\n- [ReTV](https://retv-project.eu) \u2013 video analysis & summarization (Modul Univesrity, Austria)\n- [VGG Image Annotator](https://www.robots.ox.ac.uk/~vgg/software/via/) \u2013 manual annotation software for image, audio and video\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8777130924564451,
      "result": {
        "original_header": "Indexing and classification",
        "type": "Text_excerpt",
        "value": "- [Annif](https://annif.org) and [associated tutorial](https://github.com/NatLibFi/Annif-tutorial) \u2013 tool for automated subject indexing and classification (National Library of Finland)\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9738362082176794,
      "result": {
        "original_header": "Search and retrieval",
        "type": "Text_excerpt",
        "value": "- [GallicaPix](https://gallicapix.bnf.fr/rest?run=findIllustrations-form.xq) \u2013 retrieval of heritage images (Biblioth\u00e8que nationale de France)\n- [GallicaSNOOP](https://www.bnf.fr/sites/default/files/2022-05/Poster_Gallica_Snoop.pdf) \u2013 framework for large-scale content-based image retrieval (Biblioth\u00e8que nationale de France)\n- [Maken Similarity Service](https://www.nb.no/maken/) \u2013 tools for alternative reading & finding similar photographs (National Library of Norway)\n- [Semantic search for Nasjonalmuseet\u2019s online collection](https://beta.nasjonalmuseet.no/2023/08/add-semantic-search-to-a-online-collection/) \u2013 open beta test (National Museum of Norway)\n- [VGG Text Search (VTS) Engine](https://www.robots.ox.ac.uk/~vgg/software/vts/) \u2013 search for text strings over a user-defined image set\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.974119901075072,
      "result": {
        "original_header": "Applications of Transformers, LLMs, and GPT",
        "type": "Text_excerpt",
        "value": "- [BERTopic](https://maartengr.github.io/BERTopic/index.html) \u2013 topic modeling technique that leverages Transformers and c-TF-IDF\n- [Chatbot for Luxembourgish newspapers](https://chat.eluxemburgensia.lu/login?next=/) \u2013 uses ChatGPT and understands French, German and English (Biblioth\u00e8que nationale de Luxembourg)\n- [Norwegian Transformer Model (NoTraM)](https://github.com/NBAiLab/notram#readme) \u2013 transformer model for Norwegian and Nordic languages (National Library of Norway)\n- [Swedish BERT](https://github.com/Kungbib/swedish-bert-models#readme) \u2013 BERT model for the Swedish language (Royal Library of Sweden)\n- [Visual AI](https://www.robots.ox.ac.uk/~vgg/projects/visualai/index.html) \u2013 open-world interpretable visual transformer (UK) \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9627613912399737,
      "result": {
        "original_header": "Datasets available elsewhere",
        "type": "Text_excerpt",
        "value": "- [Gensim datasets](https://github.com/piskvorky/gensim-data#readme) \u2013 repository of datasets for unstructured text processing\n- [HTR datasets in Zenodo](https://zenodo.org/search?q=metadata.subjects.subject%3A%22handwritten%20text%20recognition%22&l=list&p=1&s=10&sort=bestmatch) \u2013 subject search in Zenodo\n- [HTR-United](https://htr-united.github.io) \u2013 datasets for training transcription or segmentation models\n- [Kaggle datasets](https://www.kaggle.com/datasets)\n- [nlp-datasets](https://github.com/niderhoff/nlp-datasets#readme) \u2013 free/public domain datasets with text data for use in NLP\n- [Open Library data dumps](https://openlibrary.org/developers/dumps) \u2013 from the Internet Archive\n- [Open data collections from the National Library of Scotland](https://data.nls.uk/)\n- [Registry of Open Data on AWS](https://registry.opendata.aws) \u2013 datasets tagged by topic \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9144957356145639,
      "result": {
        "original_header": "Project lists &amp; directories",
        "type": "Text_excerpt",
        "value": "- [Inventory of NARA Artificial Intelligence (AI) Use Cases](https://www.archives.gov/data/ai-inventory) - the US National Archives and Records Administration (NARA)'s inventory of AI use cases\n- [List of Artificial Intelligence (AI) initiatives in museums](https://docs.google.com/spreadsheets/d/1A7IVnucQZ0ICxYSOCjqQ1oV3xGgNzDKtIYGrk6smV7w/edit#gid=0) \u2013 compiled in 2021 by Elena Villaespesa, Oonagh Murphy and Kate Nadel for the [Museums+AI Network](https://themuseumsai.network) project.\n- [Projects in AI Registry (PAIR)](https://libraries.ou.edu/content/project-highlight-projects-ai-registry-pair) \u2013 registry of AI projects in higher education (U. Oklahoma Libraries, USA)\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9153049029376297,
      "result": {
        "original_header": "Surveys of policies and recommendations",
        "type": "Text_excerpt",
        "value": "- [A cluster analysis of national AI strategies](https://www.brookings.edu/articles/a-cluster-analysis-of-national-ai-strategies/) \u2013 Brookings Institute analysis of different countries\u2019 national AI strategies, Dec. 2023\n- [A principled governance for emerging AI regimes: lessons from China, the European Union, and the United States](https://link.springer.com/article/10.1007/s43681-022-00205-0) by R. B. L. Dixon in _AI and Ethics_, 3, 793\u2013810, 2023\n- [AI Governance Alliance: Briefing Paper Series](https://www.weforum.org/publications/ai-governance-alliance-briefing-paper-series/) \u2013 by the World Economic Forum, Jan. 2024\n- [AI policies across the globe: Implications and recommendations for libraries](https://doi.org/10.1177/0340035223119617) by L.&nbsp;S. Lo in _IFLA Journal_, 49(4), 645\u2013649, 2023\n- [Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI](http://dx.doi.org/10.2139/ssrn.3518482) by Fjeld et al, Berkman Klein Center Research Publication No. 2020-1, 2020\n- [What ethics do I need to consider when using AI?](https://www.muchaduabout.com/post/what-ethics-do-i-need-to-consider-when-using-ai) \u2013 blog posting by Livi Adu, Nov. 2023\n- [Responsible AI in Libraries and Archives](https://www.lib.montana.edu/responsible-ai/) - IMLS funded project to produce tools and strategies that support responsible use of AI in the field (2022-2025)\n \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9054066669183692,
      "result": {
        "original_header": "Frameworks",
        "type": "Text_excerpt",
        "value": "- [A Comprehensive AI Policy Education Framework for University Teaching and Learning](https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-023-00408-3) by C. K. Y. Chan in _International Journal of Educational Technology in Higher Education_, 20(38), 2023.\n- [A Framework for U.S. AI Governance: Creating a Safe and Thriving AI Sector](https://computing.mit.edu/wp-content/uploads/2023/11/AIPolicyBrief.pdf) white paper by the MIT Schwarzman College of Computing, Dec. 11, 2023. (See also [related article in MIT News](https://news.mit.edu/2023/mit-group-releases-white-papers-governance-ai-1211).)\n- [LC Labs Artificial Intelligence Planning Framework](https://blogs.loc.gov/thesignal/2023/11/introducing-the-lc-labs-artificial-intelligence-planning-framework/\n) \u2013 US Library of Congress planning framework for responsible exploration and adoption of AI\n  - French translation: [Planification de projets IA dans les GLAM](https://github.com/altomator/Planification-de-projets-IA) \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.8891001730223631,
      "result": {
        "original_header": "Upcoming Conferences and Workshops",
        "type": "Text_excerpt",
        "value": "\ud83d\udc4b\ud83c\udffb **Note**: AI4LAM's [conferences tracker Google sheet](https://docs.google.com/spreadsheets/d/1jO8dKt0CuhZKq382OZRdMSGOU3OpJhgK2nJ-FAynbeo/edit#gid=1287495458) has a more complete list of events. The following is a list of larger and/or especially relevant events for AI4LAM. \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    },
    {
      "confidence": 0.9320697348925528,
      "result": {
        "original_header": "Contributions",
        "type": "Text_excerpt",
        "value": "Your help and participation in enhancing this awesome list are very much welcome! Please use the [issue ticket system](https://github.com/AI4LAM/awesome-ai4lam/issues) to request additions or changes, or to make other contributions to this repository. For more information, please visit the [guidelines for contributing](CONTRIBUTING.md). \n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "supervised_classification"
    }
  ],
  "development_status": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "active"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "download_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/AI4LAM/awesome-ai4lam/releases"
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 10
      },
      "technique": "GitHub_API"
    }
  ],
  "forks_url": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AI4LAM/awesome-ai4lam/forks"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "AI4LAM/awesome-ai4lam"
      },
      "technique": "GitHub_API"
    }
  ],
  "full_title": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Awesome AI for LAM "
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "identifier": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "awesome-ai4lam"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "images": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/awesome-list-badge.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition-small.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/suggest-addition.svg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/cc0.jpg"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "regular_expression"
    }
  ],
  "issue_tracker": [
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://api.github.com/repos/AI4LAM/awesome-ai4lam/issues"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://github.com/mhucka/awesome-ai4lam/issues"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "keywords": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "ai, ai-in-libraries, artificial-intelligence, awesome, awesome-list, awesome-lists, awesome-resources, libraries, library-automation, library-systems, machine-learning, machine-learning-projects, machinelearning, ml-in-libraries, natural-language-processing"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": [
          "archives",
          "artificial intelligence",
          "automation",
          "computer vision",
          "handwritten text recognition",
          "HTR",
          "libraries",
          "library information management systems",
          "library systems",
          "machine learning",
          "ML",
          "natural language processing",
          "NLP",
          "OCR",
          "optical character recognition",
          "software"
        ]
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "license": [
    {
      "confidence": 1,
      "result": {
        "name": "Creative Commons Zero v1.0 Universal",
        "spdx_id": "CC0-1.0",
        "type": "License",
        "url": "https://api.github.com/licenses/cc0-1.0",
        "value": "https://api.github.com/licenses/cc0-1.0"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "File_dump",
        "value": "Creative Commons Legal Code\n\nCC0 1.0 Universal\n\n    CREATIVE COMMONS CORPORATION IS NOT A LAW FIRM AND DOES NOT PROVIDE\n    LEGAL SERVICES. DISTRIBUTION OF THIS DOCUMENT DOES NOT CREATE AN\n    ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES THIS\n    INFORMATION ON AN \"AS-IS\" BASIS. CREATIVE COMMONS MAKES NO WARRANTIES\n    REGARDING THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS\n    PROVIDED HEREUNDER, AND DISCLAIMS LIABILITY FOR DAMAGES RESULTING FROM\n    THE USE OF THIS DOCUMENT OR THE INFORMATION OR WORKS PROVIDED\n    HEREUNDER.\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator\nand subsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for\nthe purpose of contributing to a commons of creative, cultural and\nscientific works (\"Commons\") that the public can reliably and without fear\nof later claims of infringement build upon, modify, incorporate in other\nworks, reuse and redistribute as freely as possible in any form whatsoever\nand for any purposes, including without limitation commercial purposes.\nThese owners may contribute to the Commons to promote the ideal of a free\nculture and the further production of creative, cultural and scientific\nworks, or to gain reputation or greater distribution for their Work in\npart through the use and efforts of others.\n\nFor these and/or other purposes and motivations, and without any\nexpectation of additional consideration or compensation, the person\nassociating CC0 with a Work (the \"Affirmer\"), to the extent that he or she\nis an owner of Copyright and Related Rights in the Work, voluntarily\nelects to apply CC0 to the Work and publicly distribute the Work under its\nterms, with knowledge of his or her Copyright and Related Rights in the\nWork and the meaning and intended legal effect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not\nlimited to, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display,\n     communicate, and translate a Work;\n ii. moral rights retained by the original author(s) and/or performer(s);\niii. publicity and privacy rights pertaining to a person's image or\n     likeness depicted in a Work;\n iv. rights protecting against unfair competition in regards to a Work,\n     subject to the limitations in paragraph 4(a), below;\n  v. rights protecting the extraction, dissemination, use and reuse of data\n     in a Work;\n vi. database rights (such as those arising under Directive 96/9/EC of the\n     European Parliament and of the Council of 11 March 1996 on the legal\n     protection of databases, and under any national implementation\n     thereof, including any amended or successor version of such\n     directive); and\nvii. other similar, equivalent or corresponding rights throughout the\n     world based on applicable law or treaty, and any national\n     implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention\nof, applicable law, Affirmer hereby overtly, fully, permanently,\nirrevocably and unconditionally waives, abandons, and surrenders all of\nAffirmer's Copyright and Related Rights and associated claims and causes\nof action, whether now known or unknown (including existing as well as\nfuture claims and causes of action), in the Work (i) in all territories\nworldwide, (ii) for the maximum duration provided by applicable law or\ntreaty (including future time extensions), (iii) in any current or future\nmedium and for any number of copies, and (iv) for any purpose whatsoever,\nincluding without limitation commercial, advertising or promotional\npurposes (the \"Waiver\"). Affirmer makes the Waiver for the benefit of each\nmember of the public at large and to the detriment of Affirmer's heirs and\nsuccessors, fully intending that such Waiver shall not be subject to\nrevocation, rescission, cancellation, termination, or any other legal or\nequitable action to disrupt the quiet enjoyment of the Work by the public\nas contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason\nbe judged legally invalid or ineffective under applicable law, then the\nWaiver shall be preserved to the maximum extent permitted taking into\naccount Affirmer's express Statement of Purpose. In addition, to the\nextent the Waiver is so judged Affirmer hereby grants to each affected\nperson a royalty-free, non transferable, non sublicensable, non exclusive,\nirrevocable and unconditional license to exercise Affirmer's Copyright and\nRelated Rights in the Work (i) in all territories worldwide, (ii) for the\nmaximum duration provided by applicable law or treaty (including future\ntime extensions), (iii) in any current or future medium and for any number\nof copies, and (iv) for any purpose whatsoever, including without\nlimitation commercial, advertising or promotional purposes (the\n\"License\"). The License shall be deemed effective as of the date CC0 was\napplied by Affirmer to the Work. Should any part of the License for any\nreason be judged legally invalid or ineffective under applicable law, such\npartial invalidity or ineffectiveness shall not invalidate the remainder\nof the License, and in such case Affirmer hereby affirms that he or she\nwill not (i) exercise any of his or her remaining Copyright and Related\nRights in the Work or (ii) assert any associated claims and causes of\naction with respect to the Work, in either case contrary to Affirmer's\nexpress Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n a. No trademark or patent rights held by Affirmer are waived, abandoned,\n    surrendered, licensed or otherwise affected by this document.\n b. Affirmer offers the Work as-is and makes no representations or\n    warranties of any kind concerning the Work, express, implied,\n    statutory or otherwise, including without limitation warranties of\n    title, merchantability, fitness for a particular purpose, non\n    infringement, or the absence of latent or other defects, accuracy, or\n    the present or absence of errors, whether or not discoverable, all to\n    the greatest extent permissible under applicable law.\n c. Affirmer disclaims responsibility for clearing rights of other persons\n    that may apply to the Work or any use thereof, including without\n    limitation any person's Copyright and Related Rights in the Work.\n    Further, Affirmer disclaims responsibility for obtaining any necessary\n    consents, permissions or other rights required for any use of the\n    Work.\n d. Affirmer understands and acknowledges that Creative Commons is not a\n    party to this document and has no duty or obligation with respect to\n    this CC0 or use of the Work.\n"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/LICENSE",
      "technique": "file_exploration"
    },
    {
      "confidence": 1,
      "result": {
        "identifier": "https://spdx.org/licenses/https://github.com/mhucka/awesome-ai4lam/blob/main/LICENSE",
        "spdx_id": "https://github.com/mhucka/awesome-ai4lam/blob/main/LICENSE",
        "type": "License",
        "value": "https://github.com/mhucka/awesome-ai4lam/blob/main/LICENSE"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "original_header": "License",
        "parent_header": [
          "Awesome AI for LAM <a href=\"https://github.com/sindresorhus/awesome\"><img alt=\"Awesome\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/awesome-list-badge.svg\" /></a>"
        ],
        "type": "Text_excerpt",
        "value": "<img align=\"right\" title=\"CC0 Logo\" alt=\"CC0 Logo\" src=\"https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/.graphics/cc0.jpg\" width=\"100rem\"/>\n\nThe contents of this page are licensed under the [Creative Commons CC0 1.0 Universal license](https://creativecommons.org/public-domain/cc0/). CC0 is a &ldquo;no rights reserved&rdquo; license; the authors relinquish copyright and similar rights to the contents of the Awesome AI for LAM list.\n"
      },
      "source": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md",
      "technique": "header_analysis"
    }
  ],
  "name": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "awesome-ai4lam"
      },
      "technique": "GitHub_API"
    },
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "Awesome AI for LAM"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    }
  ],
  "owner": [
    {
      "confidence": 1,
      "result": {
        "type": "Organization",
        "value": "AI4LAM"
      },
      "technique": "GitHub_API"
    }
  ],
  "programming_languages": [
    {
      "confidence": 1,
      "result": {
        "name": "SCSS",
        "size": 1097,
        "type": "Programming_language",
        "value": "SCSS"
      },
      "technique": "GitHub_API"
    }
  ],
  "readme_url": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "https://github.com/mhucka/awesome-ai4lam/blob/main/README.md"
      },
      "source": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/codemeta.json",
      "technique": "code_parser"
    },
    {
      "confidence": 1,
      "result": {
        "type": "Url",
        "value": "https://raw.githubusercontent.com/AI4LAM/awesome-ai4lam/main/README.md"
      },
      "technique": "file_exploration"
    }
  ],
  "somef_missing_categories": [
    "installation",
    "citation",
    "acknowledgement",
    "run",
    "download",
    "requirements",
    "contact",
    "contributors",
    "documentation",
    "usage",
    "faq",
    "support",
    "has_build_file",
    "executable_example"
  ],
  "somef_provenance": {
    "date": "2025-09-19 01:32:51",
    "somef_schema_version": "1.0.0",
    "somef_version": "0.9.12"
  },
  "stargazers_count": [
    {
      "confidence": 1,
      "result": {
        "type": "Number",
        "value": 136
      },
      "technique": "GitHub_API"
    }
  ],
  "type": [
    {
      "confidence": 1,
      "result": {
        "type": "String",
        "value": "non-software"
      },
      "technique": "software_type_heuristics"
    }
  ]
}